params:
  num_layers: 28
  patch_size: ${patch_size}
  num_attention_heads: 16
  attention_head_dim: 72
  in_channels: ${in_channels}
  out_channels: ${out_channels}
  norm_type: 'ada_norm_zero'
  num_embeds_ada_norm: 1000
  sample_size: ${sample_size}